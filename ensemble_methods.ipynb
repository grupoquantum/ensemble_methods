{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ensemble Methods (Métodos de Conjunto/Montagem)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Decision Tree (Árvore de Decisão):</b> é o algoritmo base dos métodos de conjunto.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado classificativo: [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
      "resultado regressivo: [[4.2], [8.555555555555555], [12.692307692307693], [16.764705882352942], [20.80952380952381], [24.84], [28.862068965517242], [32.878787878787875], [36.891891891891895], [40.90243902439025]]\n"
     ]
    }
   ],
   "source": [
    "from Neuraline.ArtificialIntelligence.MachineLearning.SupervisedLearning.ensemble_methods import DecisionTree\n",
    "ensemble_tree = DecisionTree()\n",
    "inputs = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20]]\n",
    "outputs = [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
    "ensemble_tree.fit(inputs=inputs, outputs=outputs)\n",
    "new_inputs = [[2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15], [16, 17], [18, 19], [20, 21]]\n",
    "classification = ensemble_tree.predict(inputs=new_inputs, regression=False) # para resultados classificativos atribua False ao parâmetro regression ou simplesmente o deixe ocultado\n",
    "regression = ensemble_tree.predict(inputs=new_inputs, regression=True) # para resultados regressivos atribua de forma explícita o valor True ao parâmetro regression\n",
    "print(f'resultado classificativo: {classification}')\n",
    "print(f'resultado regressivo: {regression}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Bagging (Empacotamento):</b> possui resultados mais generalistas do que os da Árvore de Decisão diminuindo as chances de sobreajuste.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado classificativo: [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
      "resultado regressivo: [[4.2], [8.555555555555555], [12.692307692307693], [16.764705882352942], [20.80952380952381], [24.84], [28.862068965517242], [32.878787878787875], [36.891891891891895], [40.90243902439025]]\n"
     ]
    }
   ],
   "source": [
    "from Neuraline.ArtificialIntelligence.MachineLearning.SupervisedLearning.ensemble_methods import Bagging\n",
    "bagging = Bagging()\n",
    "inputs = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20]]\n",
    "outputs = [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
    "bagging.fit(inputs=inputs, outputs=outputs)\n",
    "new_inputs = [[2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15], [16, 17], [18, 19], [20, 21]]\n",
    "classification = bagging.predict(inputs=new_inputs, regression=False) # para resultados classificativos atribua False ao parâmetro regression ou simplesmente o deixe ocultado\n",
    "regression = bagging.predict(inputs=new_inputs, regression=True) # para resultados regressivos atribua de forma explícita o valor True ao parâmetro regression\n",
    "print(f'resultado classificativo: {classification}')\n",
    "print(f'resultado regressivo: {regression}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Bootstrap (Inicialização Simulada):</b> é mais generalista que o anterior por que cria internamente amostras simuladas baseadas nos dados de treinamento para aumentar a generalização dos resultados.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado classificativo: [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
      "resultado regressivo: [[4.2], [8.555555555555555], [12.692307692307693], [16.764705882352942], [20.80952380952381], [24.84], [28.862068965517242], [32.878787878787875], [36.891891891891895], [40.90243902439025]]\n"
     ]
    }
   ],
   "source": [
    "from Neuraline.ArtificialIntelligence.MachineLearning.SupervisedLearning.ensemble_methods import Bootstrap\n",
    "bootstrap = Bootstrap()\n",
    "inputs = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20]]\n",
    "outputs = [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
    "bootstrap.fit(inputs=inputs, outputs=outputs)\n",
    "new_inputs = [[2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15], [16, 17], [18, 19], [20, 21]]\n",
    "classification = bootstrap.predict(inputs=new_inputs, regression=False) # para resultados classificativos atribua False ao parâmetro regression ou simplesmente o deixe ocultado\n",
    "regression = bootstrap.predict(inputs=new_inputs, regression=True) # para resultados regressivos atribua de forma explícita o valor True ao parâmetro regression\n",
    "print(f'resultado classificativo: {classification}')\n",
    "print(f'resultado regressivo: {regression}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Random Forest (Floresta Aleatória):</b> usa um conjunto de duas ou mais árvores de decisão para retornar resultados mais precisos, porém possui uma performance inferior a do algoritmo de Árvore de Decisão.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado classificativo: [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
      "resultado regressivo: [[4.2], [8.555555555555555], [12.692307692307693], [16.764705882352942], [20.80952380952381], [24.84], [28.862068965517242], [32.878787878787875], [36.891891891891895], [40.90243902439025]]\n"
     ]
    }
   ],
   "source": [
    "from Neuraline.ArtificialIntelligence.MachineLearning.SupervisedLearning.ensemble_methods import RandomForest\n",
    "ensemble_forest = RandomForest()\n",
    "inputs = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20]]\n",
    "outputs = [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
    "ensemble_forest.fit(inputs=inputs, outputs=outputs, number_of_trees=3) # number_of_trees define a quantidade de árvores na montagem do conjunto\n",
    "new_inputs = [[2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15], [16, 17], [18, 19], [20, 21]]\n",
    "classification = ensemble_forest.predict(inputs=new_inputs, regression=False) # para resultados classificativos atribua False ao parâmetro regression ou simplesmente o deixe ocultado\n",
    "regression = ensemble_forest.predict(inputs=new_inputs, regression=True) # para resultados regressivos atribua de forma explícita o valor True ao parâmetro regression\n",
    "print(f'resultado classificativo: {classification}')\n",
    "print(f'resultado regressivo: {regression}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Boosting (Impulsionamento):</b> diminui os viéses para aumentar a generalização, porém de forma mais branda para ter uma performance superior aos algoritmos anteriores.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado classificativo: [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
      "resultado regressivo: [[4.2], [8.555555555555555], [12.692307692307693], [16.764705882352942], [20.80952380952381], [24.84], [28.862068965517242], [32.878787878787875], [36.891891891891895], [40.90243902439025]]\n"
     ]
    }
   ],
   "source": [
    "from Neuraline.ArtificialIntelligence.MachineLearning.SupervisedLearning.ensemble_methods import Boosting\n",
    "boosting = Boosting()\n",
    "inputs = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20]]\n",
    "outputs = [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
    "boosting.fit(inputs=inputs, outputs=outputs)\n",
    "new_inputs = [[2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15], [16, 17], [18, 19], [20, 21]]\n",
    "classification = boosting.predict(inputs=new_inputs, regression=False) # para resultados classificativos atribua False ao parâmetro regression ou simplesmente o deixe ocultado\n",
    "regression = boosting.predict(inputs=new_inputs, regression=True) # para resultados regressivos atribua de forma explícita o valor True ao parâmetro regression\n",
    "print(f'resultado classificativo: {classification}')\n",
    "print(f'resultado regressivo: {regression}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Gradient Boosting (Impulsionamento Gradiente):</b> diminui as taxas de erro utilizando um conjunto de Árvores de Decisão que corrigem gradativamente os erros uma da outra.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado classificativo: [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
      "resultado regressivo: [[4.2], [8.555555555555555], [12.692307692307693], [16.764705882352942], [20.80952380952381], [24.84], [28.862068965517242], [32.878787878787875], [36.891891891891895], [40.90243902439025]]\n"
     ]
    }
   ],
   "source": [
    "from Neuraline.ArtificialIntelligence.MachineLearning.SupervisedLearning.ensemble_methods import GradientBoosting\n",
    "gradient_boosting = GradientBoosting()\n",
    "inputs = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20]]\n",
    "outputs = [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
    "gradient_boosting.fit(\n",
    "\tinputs=inputs,\n",
    "\toutputs=outputs,\n",
    "\testimators=3, # equivalente ao número de árvores de decisão no conjunto\n",
    "\tdepth=5, # profundidade das árvores de decisão do conjunto (número de níveis)\n",
    "\tminimum_samples_split=2, # número mínimo de alternativas para cada nó condicional da árvore\n",
    "\tlearning_rate=1 # percentual da taxa de aprendizagem na correção do erro, entre 0 (0%) e 1 (100%)\n",
    ")\n",
    "new_inputs = [[2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15], [16, 17], [18, 19], [20, 21]]\n",
    "classification = gradient_boosting.predict(inputs=new_inputs, regression=False) # para resultados classificativos atribua False ao parâmetro regression ou simplesmente o deixe ocultado\n",
    "regression = gradient_boosting.predict(inputs=new_inputs, regression=True) # para resultados regressivos atribua de forma explícita o valor True ao parâmetro regression\n",
    "print(f'resultado classificativo: {classification}')\n",
    "print(f'resultado regressivo: {regression}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Adaptive Boosting (AdaBoost):</b> é uma adaptação do algoritmo de Boosting para produzir respostas mais rápidas, isso poderá em alguns casos torná-lo menos preciso do que o Boosting.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado classificativo: [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
      "resultado regressivo: [[4.2], [8.555555555555555], [12.692307692307693], [16.764705882352942], [20.80952380952381], [24.84], [28.862068965517242], [32.878787878787875], [36.891891891891895], [40.90243902439025]]\n"
     ]
    }
   ],
   "source": [
    "from Neuraline.ArtificialIntelligence.MachineLearning.SupervisedLearning.ensemble_methods import AdaBoost\n",
    "ada_boost = AdaBoost()\n",
    "inputs = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20]]\n",
    "outputs = [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
    "ada_boost.fit(inputs=inputs, outputs=outputs)\n",
    "new_inputs = [[2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15], [16, 17], [18, 19], [20, 21]]\n",
    "classification = ada_boost.predict(inputs=new_inputs, regression=False) # para resultados classificativos atribua False ao parâmetro regression ou simplesmente o deixe ocultado\n",
    "regression = ada_boost.predict(inputs=new_inputs, regression=True) # para resultados regressivos atribua de forma explícita o valor True ao parâmetro regression\n",
    "print(f'resultado classificativo: {classification}')\n",
    "print(f'resultado regressivo: {regression}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>XGBoost (Extreme Gradient Boosting/Aumento Extremo de Gradiente):</b> é uma adaptação do algoritmo Gradient Boosting que aplica correções de erro mais severas ao algoritmo e utiliza o máximo do poder computacional do hardware para aumentar a sua velocidade de processamento. Como a correção de erros é mais extrema do que a do Gradient Boosting ele poderá generalizar menos do que o seu algoritmo de origem nas suas respostas.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado classificativo: [[3], [7], [11], [15], [23], [23], [27], [31], [35], [39]]\n",
      "resultado regressivo: [[3], [5], [7], [9], [13], [13], [15], [17], [19], [21]]\n"
     ]
    }
   ],
   "source": [
    "from Neuraline.ArtificialIntelligence.MachineLearning.SupervisedLearning.ensemble_methods import XGBoost\n",
    "xg_boost = XGBoost()\n",
    "inputs = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20]]\n",
    "outputs = [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
    "xg_boost.fit(inputs=inputs, outputs=outputs)\n",
    "new_inputs = [[2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15], [16, 17], [18, 19], [20, 21]]\n",
    "classification = xg_boost.predict(inputs=new_inputs, regression=False) # para resultados classificativos atribua False ao parâmetro regression ou simplesmente o deixe ocultado\n",
    "regression = xg_boost.predict(inputs=new_inputs, regression=True) # para resultados regressivos atribua de forma explícita o valor True ao parâmetro regression\n",
    "print(f'resultado classificativo: {classification}')\n",
    "print(f'resultado regressivo: {regression}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>LightGBM (Light Gradient Boosting Machine/Máquina de Aumento Leve de Gradiente):</b> é uma adaptação do XGBoost com o objetivo de torná-lo mais rápido, em alguns casos poderá retornar resultados menos precisos do que o XGBoost.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado classificativo: [[3], [7], [11], [15], [23], [23], [27], [31], [35], [39]]\n",
      "resultado regressivo: [[3.0], [5.0], [7.0], [9.0], [13.0], [13.0], [15.0], [17.0], [19.0], [21.0]]\n"
     ]
    }
   ],
   "source": [
    "from Neuraline.ArtificialIntelligence.MachineLearning.SupervisedLearning.ensemble_methods import LightGBM\n",
    "light_gbm = LightGBM()\n",
    "inputs = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20]]\n",
    "outputs = [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
    "light_gbm.fit(inputs=inputs, outputs=outputs)\n",
    "new_inputs = [[2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15], [16, 17], [18, 19], [20, 21]]\n",
    "classification = light_gbm.predict(inputs=new_inputs, regression=False) # para resultados classificativos atribua False ao parâmetro regression ou simplesmente o deixe ocultado\n",
    "regression = light_gbm.predict(inputs=new_inputs, regression=True) # para resultados regressivos atribua de forma explícita o valor True ao parâmetro regression\n",
    "print(f'resultado classificativo: {classification}')\n",
    "print(f'resultado regressivo: {regression}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>CatBoost (Categorical Boosting/Impulsionamento Categórico):</b> separa os dados em categorias para reduzir o número de parâmetros e aumentar a velocidade de execução, com isso ele também aumenta relativamente a generalização dos resultados de resposta. Sua velocidade e precisão está entre o Gradient Boosting e o XGBoost.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado classificativo: [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
      "resultado regressivo: [[3.0], [5.0], [7.0], [9.0], [11.0], [13.0], [15.0], [17.0], [19.0], [21.0]]\n"
     ]
    }
   ],
   "source": [
    "from Neuraline.ArtificialIntelligence.MachineLearning.SupervisedLearning.ensemble_methods import CatBoost\n",
    "cat_boost = CatBoost()\n",
    "inputs = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20]]\n",
    "outputs = [[3], [7], [11], [15], [19], [23], [27], [31], [35], [39]]\n",
    "cat_boost.fit(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    one_hot_max_size=1, # proporção relativa ao número de categarias que deverão ser otimizadas\n",
    "    cat_features=True # se True separará os dados em categorias, caso contrário manterá a estrutura original dos dados\n",
    ")\n",
    "new_inputs = [[2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15], [16, 17], [18, 19], [20, 21]]\n",
    "classification = cat_boost.predict(inputs=new_inputs, regression=False) # para resultados classificativos atribua False ao parâmetro regression ou simplesmente o deixe ocultado\n",
    "regression = cat_boost.predict(inputs=new_inputs, regression=True) # para resultados regressivos atribua de forma explícita o valor True ao parâmetro regression\n",
    "print(f'resultado classificativo: {classification}')\n",
    "print(f'resultado regressivo: {regression}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
